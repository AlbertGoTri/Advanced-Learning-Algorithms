{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51e35b8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('./deeplearning.mplstyle')\n",
    "\n",
    "RANDOM_STATE = 55 ## We will pass it to every sklearn call so we ensure reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abff22c8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Load the dataset using pandas\n",
    "df = pd.read_csv(\"heart.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e1d6bf",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cac9dc",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "cat_variables = ['Sex',\n",
    "'ChestPainType',\n",
    "'RestingECG',\n",
    "'ExerciseAngina',\n",
    "'ST_Slope'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4aec730",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# This will replace the columns with the one-hot encoded ones and keep the columns outside 'columns' argument as it is.\n",
    "df = pd.get_dummies(data = df,\n",
    "                         prefix = cat_variables,\n",
    "                         columns = cat_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c07323d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653cc32a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "features = [x for x in df.columns if x not in 'HeartDisease'] ## Removing our target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc272d50",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(len(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40ca4b8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "help(train_test_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3aef3c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(df[features], df['HeartDisease'], train_size = 0.8, random_state = RANDOM_STATE)\n",
    "\n",
    "# We will keep the shuffle = True since our dataset has not any time dependency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4082be54",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(f'train samples: {len(X_train)}')\n",
    "print(f'validation samples: {len(X_val)}')\n",
    "print(f'target proportion: {sum(y_train)/len(y_train):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085c7c51",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "min_samples_split_list = [2,10, 30, 50, 100, 200, 300, 700] ## If the number is an integer, then it is the actual quantity of samples,\n",
    "max_depth_list = [1,2, 3, 4, 8, 16, 32, 64, None] # None means that there is no depth limit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d23ccb0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "accuracy_list_train = []\n",
    "accuracy_list_val = []\n",
    "for min_samples_split in min_samples_split_list:\n",
    "    # You can fit the model at the same time you define it, because the fit function returns the fitted estimator.\n",
    "    model = DecisionTreeClassifier(min_samples_split = min_samples_split,\n",
    "                                   random_state = RANDOM_STATE).fit(X_train,y_train) \n",
    "    predictions_train = model.predict(X_train) ## The predicted values for the train dataset\n",
    "    predictions_val = model.predict(X_val) ## The predicted values for the test dataset\n",
    "    accuracy_train = accuracy_score(predictions_train,y_train)\n",
    "    accuracy_val = accuracy_score(predictions_val,y_val)\n",
    "    accuracy_list_train.append(accuracy_train)\n",
    "    accuracy_list_val.append(accuracy_val)\n",
    "\n",
    "plt.title('Train x Validation metrics')\n",
    "plt.xlabel('min_samples_split')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xticks(ticks = range(len(min_samples_split_list )),labels=min_samples_split_list)\n",
    "plt.plot(accuracy_list_train)\n",
    "plt.plot(accuracy_list_val)\n",
    "plt.legend(['Train','Validation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11d63db",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "accuracy_list_train = []\n",
    "accuracy_list_val = []\n",
    "for max_depth in max_depth_list:\n",
    "    # You can fit the model at the same time you define it, because the fit function returns the fitted estimator.\n",
    "    model = DecisionTreeClassifier(max_depth = max_depth,\n",
    "                                   random_state = RANDOM_STATE).fit(X_train,y_train) \n",
    "    predictions_train = model.predict(X_train) ## The predicted values for the train dataset\n",
    "    predictions_val = model.predict(X_val) ## The predicted values for the test dataset\n",
    "    accuracy_train = accuracy_score(predictions_train,y_train)\n",
    "    accuracy_val = accuracy_score(predictions_val,y_val)\n",
    "    accuracy_list_train.append(accuracy_train)\n",
    "    accuracy_list_val.append(accuracy_val)\n",
    "\n",
    "plt.title('Train x Validation metrics')\n",
    "plt.xlabel('max_depth')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xticks(ticks = range(len(max_depth_list )),labels=max_depth_list)\n",
    "plt.plot(accuracy_list_train)\n",
    "plt.plot(accuracy_list_val)\n",
    "plt.legend(['Train','Validation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d667511b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "decision_tree_model = DecisionTreeClassifier(min_samples_split = 50,\n",
    "                                             max_depth = 3,\n",
    "                                             random_state = RANDOM_STATE).fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf18ace7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Metrics train:\\n\\tAccuracy score: {accuracy_score(decision_tree_model.predict(X_train),y_train):.4f}\")\n",
    "print(f\"Metrics validation:\\n\\tAccuracy score: {accuracy_score(decision_tree_model.predict(X_val),y_val):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7438e1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "min_samples_split_list = [2,10, 30, 50, 100, 200, 300, 700]  ## If the number is an integer, then it is the actual quantity of samples,\n",
    "                                             ## If it is a float, then it is the percentage of the dataset\n",
    "max_depth_list = [2, 4, 8, 16, 32, 64, None]\n",
    "n_estimators_list = [10,50,100,500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d651ed44",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "accuracy_list_train = []\n",
    "accuracy_list_val = []\n",
    "for min_samples_split in min_samples_split_list:\n",
    "    # You can fit the model at the same time you define it, because the fit function returns the fitted estimator.\n",
    "    model = RandomForestClassifier(min_samples_split = min_samples_split,\n",
    "                                   random_state = RANDOM_STATE).fit(X_train,y_train) \n",
    "    predictions_train = model.predict(X_train) ## The predicted values for the train dataset\n",
    "    predictions_val = model.predict(X_val) ## The predicted values for the test dataset\n",
    "    accuracy_train = accuracy_score(predictions_train,y_train)\n",
    "    accuracy_val = accuracy_score(predictions_val,y_val)\n",
    "    accuracy_list_train.append(accuracy_train)\n",
    "    accuracy_list_val.append(accuracy_val)\n",
    "\n",
    "plt.title('Train x Validation metrics')\n",
    "plt.xlabel('min_samples_split')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xticks(ticks = range(len(min_samples_split_list )),labels=min_samples_split_list) \n",
    "plt.plot(accuracy_list_train)\n",
    "plt.plot(accuracy_list_val)\n",
    "plt.legend(['Train','Validation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0028f0a1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "accuracy_list_train = []\n",
    "accuracy_list_val = []\n",
    "for max_depth in max_depth_list:\n",
    "    # You can fit the model at the same time you define it, because the fit function returns the fitted estimator.\n",
    "    model = RandomForestClassifier(max_depth = max_depth,\n",
    "                                   random_state = RANDOM_STATE).fit(X_train,y_train) \n",
    "    predictions_train = model.predict(X_train) ## The predicted values for the train dataset\n",
    "    predictions_val = model.predict(X_val) ## The predicted values for the test dataset\n",
    "    accuracy_train = accuracy_score(predictions_train,y_train)\n",
    "    accuracy_val = accuracy_score(predictions_val,y_val)\n",
    "    accuracy_list_train.append(accuracy_train)\n",
    "    accuracy_list_val.append(accuracy_val)\n",
    "\n",
    "plt.title('Train x Validation metrics')\n",
    "plt.xlabel('max_depth')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xticks(ticks = range(len(max_depth_list )),labels=max_depth_list)\n",
    "plt.plot(accuracy_list_train)\n",
    "plt.plot(accuracy_list_val)\n",
    "plt.legend(['Train','Validation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881ac3e7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "accuracy_list_train = []\n",
    "accuracy_list_val = []\n",
    "for n_estimators in n_estimators_list:\n",
    "    # You can fit the model at the same time you define it, because the fit function returns the fitted estimator.\n",
    "    model = RandomForestClassifier(n_estimators = n_estimators,\n",
    "                                   random_state = RANDOM_STATE).fit(X_train,y_train) \n",
    "    predictions_train = model.predict(X_train) ## The predicted values for the train dataset\n",
    "    predictions_val = model.predict(X_val) ## The predicted values for the test dataset\n",
    "    accuracy_train = accuracy_score(predictions_train,y_train)\n",
    "    accuracy_val = accuracy_score(predictions_val,y_val)\n",
    "    accuracy_list_train.append(accuracy_train)\n",
    "    accuracy_list_val.append(accuracy_val)\n",
    "\n",
    "plt.title('Train x Validation metrics')\n",
    "plt.xlabel('n_estimators')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xticks(ticks = range(len(n_estimators_list )),labels=n_estimators_list)\n",
    "plt.plot(accuracy_list_train)\n",
    "plt.plot(accuracy_list_val)\n",
    "plt.legend(['Train','Validation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5c9015",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "random_forest_model = RandomForestClassifier(n_estimators = 100,\n",
    "                                             max_depth = 16, \n",
    "                                             min_samples_split = 10).fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822fea86",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Metrics train:\\n\\tAccuracy score: {accuracy_score(random_forest_model.predict(X_train),y_train):.4f}\\nMetrics test:\\n\\tAccuracy score: {accuracy_score(random_forest_model.predict(X_val),y_val):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba9dd66",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "n = int(len(X_train)*0.8) ## Let's use 80% to train and 20% to eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fde7e9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "X_train_fit, X_train_eval, y_train_fit, y_train_eval = X_train[:n], X_train[n:], y_train[:n], y_train[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6bffa0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "xgb_model = XGBClassifier(n_estimators = 500, learning_rate = 0.1,verbosity = 1, random_state = RANDOM_STATE)\n",
    "xgb_model.fit(X_train_fit,y_train_fit, eval_set = [(X_train_eval,y_train_eval)], early_stopping_rounds = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2aef5fc",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "xgb_model.best_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0fea3d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Metrics train:\\n\\tAccuracy score: {accuracy_score(xgb_model.predict(X_train),y_train):.4f}\\nMetrics test:\\n\\tAccuracy score: {accuracy_score(xgb_model.predict(X_val),y_val):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
